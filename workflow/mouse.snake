configfile: "config/config.mouse.yaml"

project=config["project"]

def get_read1_file(wildcards):
    return config["read1"][wildcards.sample]

def get_read2_file(wildcards):
    return config["read2"][wildcards.sample]

def get_normal_bam(wildcards):
    return "results/{}/base_quality_recalibration/{}.markdup.recal.bam".format(project, config["pair"][wildcards.pair][0])

def get_tumor_bam(wildcards):
    return "results/{}/base_quality_recalibration/{}.markdup.recal.bam".format(project, config["pair"][wildcards.pair][1])

def get_normal_bai(wildcards):
    return "results/{}/base_quality_recalibration/{}.markdup.recal.bai".format(project, config["pair"][wildcards.pair][0])

def get_tumor_bai(wildcards):
    return "results/{}/base_quality_recalibration/{}.markdup.recal.bai".format(project, config["pair"][wildcards.pair][1])

def get_normal_vcfs(wildcards):
    return " ".join(["-V results/{}/mutect_variant_calling_normal/{}/{}.vcf.gz".format(project, normal, normal) for normal in config["normal"]])

def get_normal_id(wildcards):
    return "{}".format(config["pair"][wildcards.pair][0])

def get_tumor_id(wildcards):
    return "{}".format(config["pair"][wildcards.pair][1])

def get_target_enrich_tempdir(wildcards):
    return "results/{}/review_target_enrichment/tmp".format(project)

def get_bam_qc_tempdir(wildcards):
    return "results/{}/bam_qc/tmp{}".format(project, wildcards.sample)

def get_base_coverage_tempdir(wildcards):
    return "results/{}/base_coverage".format(project)

rule all:
    input:
        rawqc=expand("results/{project}/raw_fastq_qc/{sample}_R1_fastqc.html", project=config["project"], sample=config["read1"]),
        trimqc=expand("results/{project}/trim_fastq_qc/{sample}_R1.trimmed_fastqc.html", project=config["project"], sample=config["read1"]),
        bam=expand("results/{project}/bwa_align/{sample}.bam", project=config["project"], sample=config["read1"]),
        markdup=expand("results/{project}/mark_dup/{sample}.markdup.bam", project=config["project"], sample=config["read1"]),
        rawstat=expand("results/{project}/bam_qc/{sample}.raw.bam.flagstat.txt", project=config["project"], sample=config["read1"]),
        cov=expand("results/{project}/base_coverage/base_coverage.txt.gz", project=config["project"]),
        recal=expand("results/{project}/base_quality_recalibration/{sample}.markdup.recal.bam", project=config["project"], sample=config["read1"]),
        rawvcf=expand("results/{project}/mutect_variant_calling/{pair}/{pair}.raw.vcf.gz", project=config["project"], pair=config["pair"]),
        filtvcf=expand("results/{project}/filter_mutect_calls/{pair}/{pair}.filtered.vcf.gz", project=config["project"], pair=config["pair"]),
        ####nvcf=expand("results/{project}/mutect_variant_calling_normal/{normal}/{normal}.vcf.gz", project=config["project"], normal=config["normal"]),
        ####db=directory(expand("results/{project}/create_genomicsdb_normal/pon_db", project=config["project"])),
        funco=expand("results/{project}/funcotator_annotate_variants/{pair}/{pair}.funcotated.vcf.gz", project=config["project"], pair=config["pair"]),
        pon=expand("results/{project}/create_panel_of_normals/pon.vcf.gz", project=config["project"]),
        ####enrich=expand("results/{project}/review_target_enrichment/{sample}/enrichment.{sample}.txt", project=config["project"], sample=config["read1"])
        ####enrich=expand("results/{project}/review_target_enrichment/C4_PBMC/enrichment.C4_PBMC.txt", project=config["project"])
        enrich=expand("results/{project}/review_target_enrichment/target_enrichment.png", project=config["project"]),
        varsum=expand("results/{project}/mafs_to_excel/variants.xlsx", project=config["project"]),
        covsum=expand("results/{project}/review_base_coverage/base.coverage.sumamry.xlsx", project=config["project"]),
        cnvcall=expand("results/{project}/cnvkit_copy_number_calling/{pair}/{pair}.call.cns", project=config["project"], pair=config["pair"]),
        cnvann=expand("results/{project}/annotate_copy_number_variations/{pair}/{pair}.call.annotated.txt.gz", project=config["project"], pair=config["pair"]),
        cnvsum=expand("results/{project}/cnvs_to_excel/cnvs.xlsx", project=config["project"])

rule rename_fastq:
    input:
        read1=get_read1_file,
        read2=get_read2_file
    output:
        read1=temp("results/{project}/rename_fastq/{sample}_R1.fastq.gz"),
        read2=temp("results/{project}/rename_fastq/{sample}_R2.fastq.gz")
    shell:
        "cp {input.read1} {output.read1}; "
        "cp {input.read2} {output.read2}"

rule raw_fastq_qc:
    input:
        read1="results/{project}/rename_fastq/{sample}_R1.fastq.gz",
        read2="results/{project}/rename_fastq/{sample}_R2.fastq.gz"
    output:
        out1="results/{project}/raw_fastq_qc/{sample}_R1_fastqc.html",
        out2="results/{project}/raw_fastq_qc/{sample}_R2_fastqc.html"
    log:
        "results/{project}/logs/raw_fastq_qc/{sample}.log"
    conda:
        "../envs/fastqc.yaml"
    threads: 4
    shell:
        "fastqc --outdir results/{project}/raw_fastq_qc --threads {threads} --quiet {input.read1} {input.read2} >{log} 2>&1"

rule trim_adapter:
    input:
        read1="results/{project}/rename_fastq/{sample}_R1.fastq.gz",
        read2="results/{project}/rename_fastq/{sample}_R2.fastq.gz"
    output:
        read1=temp("results/{project}/trim_fastq/{sample}_R1.trimmed.fastq.gz"),
        read2=temp("results/{project}/trim_fastq/{sample}_R2.trimmed.fastq.gz")
    params:
        overlap=config["overlap"],
        errate=config["errate"],
        adapter3=config["adapter3"],
        adapter5=config["adapter5"],
        minlen=config["minlen"],
        qscore=config["qscore"]
    log:
        "results/{project}/logs/trim_fastq/{sample}.log",
    threads: 4
    conda:
        "../envs/cutadapt.yaml"
    shell:
        "cutadapt -j {threads} -O {params.overlap} -e {params.errate} -m {params.minlen} -q {params.qscore},{params.qscore} -a {params.adapter3} -A {params.adapter5} -o {output.read1} -p {output.read2} {input.read1} {input.read2} >{log} 2>&1; "

rule trim_fastq_qc:
    input:
        read1="results/{project}/trim_fastq/{sample}_R1.trimmed.fastq.gz",
        read2="results/{project}/trim_fastq/{sample}_R2.trimmed.fastq.gz"
    output:
        out1="results/{project}/trim_fastq_qc/{sample}_R1.trimmed_fastqc.html",
        out2="results/{project}/trim_fastq_qc/{sample}_R2.trimmed_fastqc.html"
    log:
        "results/{project}/logs/trim_fastq_qc/{sample}.log"
    conda:
        "../envs/fastqc.yaml"
    threads: 4
    shell:
        "fastqc --outdir results/{project}/trim_fastq_qc --threads {threads} --quiet {input.read1} {input.read2} >{log} 2>&1"

rule bwa_align:
    input:
        read1="results/{project}/trim_fastq/{sample}_R1.trimmed.fastq.gz",
        read2="results/{project}/trim_fastq/{sample}_R2.trimmed.fastq.gz"
    output:
        sam=temp("results/{project}/bwa_align/{sample}.sam"),
        bam="results/{project}/bwa_align/{sample}.bam",
        bai="results/{project}/bwa_align/{sample}.bai",
        tmp=temp(directory("results/{project}/bwa_align/tmp{sample}"))
    resources:
        mem_mb=16000
    params:
        bwaidx=config["bwaidx"]
    log:
        bwa="results/{project}/logs/bwa_align/bwa.{sample}.log",
        picard="results/{project}/logs/bwa_align/picard.sortsam.{sample}.log"
    threads: 8
    conda:
        "../envs/bwa.yaml"
    shell:
        """bwa mem -M -t {threads} -R "@RG\\tID:{wildcards.sample}\\tLB:{wildcards.sample}\\tSM:{wildcards.sample}\\tPL:ILLUMINA" {params.bwaidx} {input.read1} {input.read2} >{output.sam} 2>{log.bwa}; """
        """picard SortSam SORT_ORDER=coordinate INPUT={output.sam} OUTPUT={output.bam} VALIDATION_STRINGENCY=LENIENT CREATE_INDEX=true TMP_DIR={output.tmp} >{log.picard} 2>&1; """

rule mark_dup:
    input:
        bam="results/{project}/bwa_align/{sample}.bam",
        bai="results/{project}/bwa_align/{sample}.bai"
    output:
        tmp=temp(directory("results/{project}/mark_dup/tmp{sample}")),
        reorder=temp("results/{project}/mark_dup/{sample}.reorder.bam"),
        qsort=temp("results/{project}/mark_dup/{sample}.qsorted.bam"),
        markdup=temp("results/{project}/mark_dup/{sample}.qsorted.markdup.bam"),
        metric="results/{project}/mark_dup/{sample}.markdup_metrics.txt",
        bam="results/{project}/mark_dup/{sample}.markdup.bam",
        bai="results/{project}/mark_dup/{sample}.markdup.bai"
    resources:
        mem_mb=16000
    params:
        refdict=config["refdict"]
    log:
        reorder="results/{project}/logs/mark_dup/picard.reorder.{sample}.log",
        qsort="results/{project}/logs/mark_dup/picard.qsort.{sample}.log",
        markdup="results/{project}/logs/mark_dup/picard.markdup.{sample}.log",
        csort="results/{project}/logs/mark_dup/picard.osort.{sample}.log"
    conda:
        "../envs/bwa.yaml"
    shell:
        """picard ReorderSam INPUT={input.bam} OUTPUT={output.reorder} SEQUENCE_DICTIONARY={params.refdict} VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.reorder} 2>&1; """
        """picard SortSam SORT_ORDER=queryname INPUT={output.reorder} OUTPUT={output.qsort} VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.qsort} 2>&1; """
        """picard MarkDuplicates INPUT={output.qsort} OUTPUT={output.markdup} METRICS_FILE={output.metric} ASSUME_SORT_ORDER=queryname VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.markdup} 2>&1; """
        """picard SortSam SORT_ORDER=coordinate INPUT={output.markdup} OUTPUT={output.bam} CREATE_INDEX=true VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.csort} 2>&1; """

rule bam_qc:
    input:
        rawbam="results/{project}/bwa_align/{sample}.bam",
        rawbai="results/{project}/bwa_align/{sample}.bai",
        mdbam="results/{project}/mark_dup/{sample}.markdup.bam",
        mdbai="results/{project}/mark_dup/{sample}.markdup.bai"
    output:
        rawstat="results/{project}/bam_qc/{sample}.raw.bam.flagstat.txt",
        mdstat="results/{project}/bam_qc/{sample}.markdup.bam.flagstat.txt",
        insm="results/{project}/bam_qc/{sample}.insert_size_metrics.txt",
        insp="results/{project}/bam_qc/{sample}.insert_size_histogram.pdf"
    resources:
        mem_mb=16000,
        tmpdir=get_bam_qc_tempdir
    log:
        samtools="results/{project}/logs/bam_qc/samtools.{sample}.log",
        picard="results/{project}/logs/bam_qc/picard.insertsize.{sample}.log"
    conda:
        "../envs/bwa.yaml"
    shell:
        """samtools flagstat {input.rawbam} >{output.rawstat} 2>{log.samtools}; """
        """samtools flagstat {input.mdbam} >{output.mdstat} 2>>{log.samtools}; """
        """picard CollectInsertSizeMetrics INPUT={input.mdbam} OUTPUT={output.insm} HISTOGRAM_FILE={output.insp} ASSUME_SORTED=True METRIC_ACCUMULATION_LEVEL=ALL_READS VALIDATION_STRINGENCY=LENIENT >{log.picard} 2>&1; """

rule base_coverage:
    input:
        bam=expand("results/{project}/mark_dup/{sample}.markdup.bam", project=config["project"], sample=config["read1"]),
        bai=expand("results/{project}/mark_dup/{sample}.markdup.bai", project=config["project"], sample=config["read1"])
    output:
        cov="results/{project}/base_coverage/base_coverage.txt.gz"
    params:
        bed=config["cleanbed"]
    resources:
        tmpdir=get_base_coverage_tempdir
    log:
        "results/{project}/logs/base_coverage/samtools.depth.log"
    threads: 8
    conda:
        "../envs/bwa.yaml"
    shell:
        "samtools depth -a -d 0 -Q 1 -@ {threads} -b {params.bed} {input.bam} >results/{project}/base_coverage/base_coverage.txt 2>{log}; "
        "gzip results/{project}/base_coverage/base_coverage.txt; "

rule review_base_coverage:
    input:
        cov="results/{project}/base_coverage/base_coverage.txt.gz"
    output:
        report="results/{project}/review_base_coverage/base.coverage.sumamry.xlsx",
        tempbed=temp("results/{project}/review_base_coverage/lowcov.bases.bed"),
        lowcov="results/{project}/review_base_coverage/low.coverage.regions.bed"
    params:
        bed=config["bed"]
    log:
        "results/{project}/logs/review_base_coverage/review_base_coverage.log"
    conda:
        "../envs/python.yaml"
    script:
        "../scripts/review_base_coverage.py"

#rule review_target_enrichment:
#    input:
#        bam="results/{project}/mark_dup/{sample}.markdup.bam",
#        bai="results/{project}/mark_dup/{sample}.markdup.bai"
#    output:
#        report="results/{project}/review_target_enrichment/{sample}/enrichment.{sample}.txt"
#    params:
#        bed=config["bed"]
#    resources:
#        tmpdir="results/{project}/review_target_enrichment/tmp{sample}"
#    log:
#        "results/{project}/logs/review_target_enrichment/{sample}.log",
#        "results/{project}/logs/review_target_enrichment/{sample}.msg"
#    conda:
#        "../envs/python.yaml"
#    script:
#        "../scripts/review_target_enrichment.py"

rule review_target_enrichment:
    input:
        bam=expand("results/{project}/mark_dup/{sample}.markdup.bam", project=config["project"], sample=config["read1"]),
        bai=expand("results/{project}/mark_dup/{sample}.markdup.bai", project=config["project"], sample=config["read1"])
    output:
        txt="results/{project}/review_target_enrichment/target_enrichment.txt",
        plot="results/{project}/review_target_enrichment/target_enrichment.png"
    params:
        bed=config["cleanbed"],
        pw=config["plotwidth"],
        ph=config["plotheight"]
    resources:
        tmpdir=get_target_enrich_tempdir
    log:
        "results/{project}/logs/review_target_enrichment/deeptools.plotenrichment.log"
    threads: 16
    conda:
        "../envs/deeptools.yaml"
    shell:
        """plotEnrichment -b {input.bam} --BED {params.bed} --regionLabels "reads on target" """
        """-o {output.plot} --outRawCounts {output.txt} -p {threads} --smartLabels """
        """--plotHeight {params.ph} --plotWidth {params.pw} >{log} 2>&1; """

rule base_quality_recalibration:
    input:
        bam="results/{project}/mark_dup/{sample}.markdup.bam",
        bai="results/{project}/mark_dup/{sample}.markdup.bai"
    output:
        tmp=temp(directory("results/{project}/base_quality_recalibration/tmp{sample}")),
        recal="results/{project}/base_quality_recalibration/{sample}.recal_data.table",
        bam="results/{project}/base_quality_recalibration/{sample}.markdup.recal.bam",
        bai="results/{project}/base_quality_recalibration/{sample}.markdup.recal.bai"
    params:
        refseq=config["refseq"],
        snpdb=config["snpdb"]
    resources:
        mem_mb=16000
    log:
        br="results/{project}/logs/base_quality_recalibration/gatk.BaseRecalibrator.{sample}.log",
        ab="results/{project}/logs/base_quality_recalibration/gatk.ApplyBQSR.{sample}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk BaseRecalibrator --tmp-dir {output.tmp}  -I {input.bam} -R {params.refseq} --known-sites {params.snpdb} -O {output.recal} >{log.br} 2>&1; """
        """gatk ApplyBQSR --tmp-dir {output.tmp} -R {params.refseq}  -I {input.bam} --bqsr-recal-file {output.recal} -O {output.bam} >{log.ab} 2>&1; """

rule mutect_variant_calling:
    input:
        normal=get_normal_bam,
        tumor=get_tumor_bam,
        pon="results/{project}/create_panel_of_normals/pon.vcf.gz"
    output:
        tmp=temp(directory("results/{project}/mutect_variant_calling/tmp{pair}")),
        roa="results/{project}/mutect_variant_calling/{pair}/{pair}.f1r2.tar.gz",
        vcf="results/{project}/mutect_variant_calling/{pair}/{pair}.raw.vcf.gz",
        bam="results/{project}/mutect_variant_calling/{pair}/{pair}.reassembled.bam"
    params:
        refseq=config["refseq"],
        bed=config["cleanbed"]
    resources:
        mem_mb=16000
    threads: 8
    log:
        "results/{project}/logs/mutect_variant_calling/gatk.mutect2.{pair}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """x=`basename {input.normal}`; """
        """sid=${{x%.markdup.recal.bam}}; """
        """mkdir -p {output.tmp}; """
        """gatk Mutect2 --tmp-dir {output.tmp} -R {params.refseq} """
        """-I {input.tumor} -I {input.normal} -normal ${{sid}} -L {params.bed} """
        """--panel-of-normals {input.pon} --f1r2-tar-gz {output.roa} """
        """-bamout {output.bam} -O {output.vcf} >{log} 2>&1; """

# LearnReadOrientationModel
rule learn_read_orientation_model:
    input:
        roa="results/{project}/mutect_variant_calling/{pair}/{pair}.f1r2.tar.gz"
    output:
        tmp=temp(directory("results/{project}/learn_read_orientation_model/tmp{pair}")),
        mdl="results/{project}/learn_read_orientation_model/{pair}/{pair}.read-orientation-model.tar.gz"
    resources:
        mem_mb=12000
    threads: 4
    log:
        "results/{project}/logs/learn_read_orientation_model/gatk.learnreadorientationmodel.{pair}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk LearnReadOrientationModel --tmp-dir {output.tmp} -I {input.roa} -O {output.mdl} >{log} 2>&1; """

# pass the learned read orientation model to FilterMutectCallswith the -ob-priors argument
rule filter_mutect_calls:
    input:
        vcf="results/{project}/mutect_variant_calling/{pair}/{pair}.raw.vcf.gz",
        #seg="results/{project}/estimate_contamination/{pair}/{pair}.segments.tsv",
        #ctm="results/{project}/estimate_contamination/{pair}/{pair}.contamination.table",
        mdl="results/{project}/learn_read_orientation_model/{pair}/{pair}.read-orientation-model.tar.gz"
    output:
        tmp=temp(directory("results/{project}/filter_mutect_calls/tmp{pair}")),
        vcf="results/{project}/filter_mutect_calls/{pair}/{pair}.filtered.vcf.gz"
    params:
        refseq=config["refseq"]
    resources:
        mem_mb=16000
    threads: 4
    log:
        "results/{project}/logs/filter_mutect_calls/gatk.filtermutectcalls.{pair}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk FilterMutectCalls --tmp-dir {output.tmp} """
        """-R {params.refseq} -V {input.vcf} """
        """--ob-priors {input.mdl} -O {output.vcf} >{log} 2>&1; """

# Run Mutect2 in tumor-only mode for each normal sample, for creating PON
rule mutect_variant_calling_normal:
    input:
        bam="results/{project}/base_quality_recalibration/{normal}.markdup.recal.bam"
    output:
        tmp=temp(directory("results/{project}/mutect_variant_calling_normal/tmp{normal}")),
        vcf="results/{project}/mutect_variant_calling_normal/{normal}/{normal}.vcf.gz"
    params:
        refseq=config["refseq"],
        bed=config["cleanbed"]
    resources:
        mem_mb=16000
    threads: 4
    log:
        "results/{project}/logs/mutect_variant_calling_normal/gatk.mutect2.{normal}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk Mutect2 --tmp-dir {output.tmp} -R {params.refseq} """
        """-I {input.bam} -max-mnp-distance 0 -L {params.bed} """
        """-O {output.vcf} >{log} 2>&1; """

# Create a GenomicsDB from the normal Mutect2 calls.
rule create_genomicsdb_normal:
    input:
        vcf=expand("results/{project}/mutect_variant_calling_normal/{normal}/{normal}.vcf.gz", project=config["project"], normal=config["normal"])
    output:
        tmp=temp(directory("results/{project}/create_genomicsdb_normal/tmp")),
        db=temp(directory("results/{project}/create_genomicsdb_normal/pon_db"))
    params:
        refseq=config["refseq"],
        bed=config["cleanbed"],
        vcf=get_normal_vcfs
    resources:
        mem_mb=12000
    threads: 4
    log:
        "results/{project}/logs/create_genomicsdb_normal/gatk.genomicsdbimport.normal.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk GenomicsDBImport --tmp-dir {output.tmp} -R {params.refseq} -L {params.bed} """
        """--genomicsdb-workspace-path {output.db} --merge-input-intervals {params.vcf} >{log} 2>&1; """

# Combine the normal calls using CreateSomaticPanelOfNormals.
rule create_panel_of_normals:
    input:
        db="results/{project}/create_genomicsdb_normal/pon_db"
    output:
        tmp=temp(directory("results/{project}/create_panel_of_normals/tmp")),
        vcf="results/{project}/create_panel_of_normals/pon.vcf.gz"
    params:
        refseq=config["refseq"]
    resources:
        mem_mb=12000
    threads: 4
    log:
        "results/{project}/logs/create_panel_of_normals/gatk.createsomaticpanelofnormals.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk CreateSomaticPanelOfNormals --tmp-dir {output.tmp} -R {params.refseq} -V gendb://{input.db} -O {output.vcf} >{log} 2>&1; """

# Annotate variants using Funcotator.
rule funcotator_annotate_variants:
    input:
        vcf="results/{project}/filter_mutect_calls/{pair}/{pair}.filtered.vcf.gz"
    output:
        tmp=temp(directory("results/{project}/funcotator_annotate_variants/tmp{pair}")),
        vcf="results/{project}/funcotator_annotate_variants/{pair}/{pair}.funcotated.vcf.gz",
        maftmp=temp("results/{project}/funcotator_annotate_variants/{pair}/{pair}.funcotated.maf"),
        maf="results/{project}/funcotator_annotate_variants/{pair}/{pair}.funcotated.maf.gz"
    params:
        refseq=config["refseq"],
        funco=config["funco"],
        refver=config["refver"],
        mafilt=config["mafilt"],
        normal=get_normal_id,
        tumor=get_tumor_id
    resources:
        mem_mb=8000
    threads: 2
    log:
        vcf="results/{project}/logs/funcotator_annotate_variants/gatk.funcotator.{pair}.vcf.log",
        maf="results/{project}/logs/funcotator_annotate_variants/gatk.funcotator.{pair}.maf.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk Funcotator --tmp-dir {output.tmp} -R {params.refseq} -V {input.vcf} """
        """-O {output.vcf} --output-file-format VCF --ref-version {params.refver} """
        """--data-sources-path {params.funco} --remove-filtered-variants False >{log.vcf} 2>&1; """
        """gatk Funcotator --tmp-dir {output.tmp} -R {params.refseq} -V {input.vcf} """
        """-O {output.maftmp} --output-file-format MAF --ref-version {params.refver} """
        """--data-sources-path {params.funco} --remove-filtered-variants {params.mafilt} """
        """--annotation-default Center:grcf --annotation-default Tumor_Sample_Barcode:{params.tumor} """
        """--annotation-default Matched_Norm_Sample_Barcode:{params.normal} >{log.maf} 2>&1; """
        """gzip {output.maftmp}; zcat {output.maf} >{output.maftmp}; """

# Combine MAFs and write to an excel file
rule mafs_to_excel:
    input:
        maf=expand("results/{project}/funcotator_annotate_variants/{pair}/{pair}.funcotated.maf.gz", project=config["project"], pair=config["pair"])
    output:
        report="results/{project}/mafs_to_excel/variants.xlsx"
    log:
        "results/{project}/logs/mafs_to_excel/combine_mafs.log"
    conda:
        "../envs/python.yaml"
    script:
        "../scripts/mafs_to_excel.py"

# call copy number variations with CNVkit
rule cnvkit_copy_number_calling:
    input:
        normalbam=get_normal_bam,
        tumorbam=get_tumor_bam,
        normalbai=get_normal_bai,
        tumorbai=get_tumor_bai
    output:
        folder=directory("results/{project}/cnvkit_copy_number_calling/{pair}"),
        ref="results/{project}/cnvkit_copy_number_calling/{pair}/reference.cnn",
        call="results/{project}/cnvkit_copy_number_calling/{pair}/{pair}.call.cns",
        cnr="results/{project}/cnvkit_copy_number_calling/{pair}/{pair}.cnr",
        cns="results/{project}/cnvkit_copy_number_calling/{pair}/{pair}.cns",
        diagram="results/{project}/cnvkit_copy_number_calling/{pair}/{pair}-diagram.pdf",
        scatter="results/{project}/cnvkit_copy_number_calling/{pair}/{pair}-scatter.png"
    params:
        refseq=config["refseq"],
        bed=config["cleanbed"]
    resources:
        mem_mb=16000
    threads: 4
    log:
        "results/{project}/logs/cnvkit_copy_number_calling/cnvkit.{pair}.log"
    conda:
        "../envs/cnvkit.yaml"
    shell:
        """touch {input.normalbai}; """
        """touch {input.tumorbai}; """
        """refseq=`basename {params.refseq}`; """
        """cp {params.refseq} {output.folder}/; """
        """cp {params.refseq}.fai {output.folder}/; """
        """touch {output.folder}/${{refseq}}.fai; """
        """cnvkit.py batch {input.tumorbam} """
        """--normal {input.normalbam} """
        """--targets {params.bed} """
        """--fasta {output.folder}/${{refseq}} """
        """--output-dir {output.folder} """
        """--processes {threads} """
        """--short-names """
        """--scatter --diagram """
        """>{log} 2>&1; """
        """x=`basename {input.tumorbam}`; """
        """tid=${{x%.markdup.recal.bam}}; """
        """mv {output.folder}/${{tid}}.markdup.call.cns {output.call}; """
        """mv {output.folder}/${{tid}}.markdup.cnr {output.cnr}; """
        """mv {output.folder}/${{tid}}.markdup.cns {output.cns}; """
        """mv {output.folder}/${{tid}}.markdup-diagram.pdf {output.diagram}; """
        """mv {output.folder}/${{tid}}.markdup-scatter.png {output.scatter}; """
        """rm {output.folder}/${{refseq}}*; """

# annotate copy number variations based on (annotated) target bed file with bedtools
rule annotate_copy_number_variations:
    input:
        call="results/{project}/cnvkit_copy_number_calling/{pair}/{pair}.call.cns"
    output:
        tempbed=temp("results/{project}/annotate_copy_number_variations/{pair}/{pair}.tmp.bed"),
        call="results/{project}/annotate_copy_number_variations/{pair}/{pair}.call.annotated.txt.gz"
    params:
        bed=config["bed"]
    log:
        "results/{project}/logs/annotate_copy_number_variations/annotate.{pair}.log"
    conda:
        "../envs/python.yaml"
    script:
        "../scripts/annotate_cnv.py"

# Combine annotated CNVs and write to an excel file
rule cnvs_to_excel:
    input:
        cnv=expand("results/{project}/annotate_copy_number_variations/{pair}/{pair}.call.annotated.txt.gz", project=config["project"], pair=config["pair"])
    output:
        report="results/{project}/cnvs_to_excel/cnvs.xlsx"
    params:
        filt=config["cnvfilt"]
    log:
        "results/{project}/logs/cnvs_to_excel/combine_cnvs.log"
    conda:
        "../envs/python.yaml"
    script:
        "../scripts/cnvs_to_excel.py"

