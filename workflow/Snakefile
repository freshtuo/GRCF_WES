configfile: "config/config.yaml"

project=config["project"]

def get_read1_file(wildcards):
    return config["read1"][wildcards.sample]

def get_read2_file(wildcards):
    return config["read2"][wildcards.sample]

def get_normal_bam(wildcards):
    return "results/{}/base_quality_recalibration/{}.markdup.recal.bam".format(project, config["pair"][wildcards.pair][0])

def get_tumor_bam(wildcards):
    return "results/{}/base_quality_recalibration/{}.markdup.recal.bam".format(project, config["pair"][wildcards.pair][1])

def get_normal_vcfs(wildcards):
    return " ".join(["-V results/{}/mutect_variant_calling_normal/{}/{}.vcf.gz".format(project, normal, normal) for normal in config["normal"]])

rule all:
    input:
        rawqc=expand("results/{project}/raw_fastq_qc/{sample}_R1_fastqc.html", project=config["project"], sample=config["read1"]),
        trimqc=expand("results/{project}/trim_fastq_qc/{sample}_R1.trimmed_fastqc.html", project=config["project"], sample=config["read1"]),
        bam=expand("results/{project}/bwa_align/{sample}.bam", project=config["project"], sample=config["read1"]),
        markdup=expand("results/{project}/mark_dup/{sample}.markdup.bam", project=config["project"], sample=config["read1"]),
        rawstat=expand("results/{project}/bam_qc/{sample}.raw.bam.flagstat.txt", project=config["project"], sample=config["read1"]),
        cov=expand("results/{project}/base_coverage/base_coverage.txt.gz", project=config["project"]),
        recal=expand("results/{project}/base_quality_recalibration/{sample}.markdup.recal.bam", project=config["project"], sample=config["read1"]),
        rawvcf=expand("results/{project}/mutect_variant_calling/{pair}/{pair}.raw.vcf.gz", project=config["project"], pair=config["pair"]),
        filtvcf=expand("results/{project}/filter_mutect_calls/{pair}/{pair}.filtered.vcf.gz", project=config["project"], pair=config["pair"]),
        #nvcf=expand("results/{project}/mutect_variant_calling_normal/{normal}/{normal}.vcf.gz", project=config["project"], normal=config["normal"]),
        #db=directory(expand("results/{project}/create_genomicsdb_normal/pon_db", project=config["project"])),
        pon=expand("results/{project}/create_panel_of_normals/pon.vcf.gz", project=config["project"])

rule rename_fastq:
    input:
        read1=get_read1_file,
        read2=get_read2_file
    output:
        read1=temp("results/{project}/rename_fastq/{sample}_R1.fastq.gz"),
        read2=temp("results/{project}/rename_fastq/{sample}_R2.fastq.gz")
    shell:
        "cp {input.read1} {output.read1}; "
        "cp {input.read2} {output.read2}"

rule raw_fastq_qc:
    input:
        read1="results/{project}/rename_fastq/{sample}_R1.fastq.gz",
        read2="results/{project}/rename_fastq/{sample}_R2.fastq.gz"
    output:
        out1="results/{project}/raw_fastq_qc/{sample}_R1_fastqc.html",
        out2="results/{project}/raw_fastq_qc/{sample}_R2_fastqc.html"
    log:
        "results/{project}/logs/raw_fastq_qc/{sample}.log"
    conda:
        "../envs/fastqc.yaml"
    threads: 4
    shell:
        "fastqc --outdir results/{project}/raw_fastq_qc --threads {threads} --quiet {input.read1} {input.read2} >{log} 2>&1"

rule trim_adapter:
    input:
        read1="results/{project}/rename_fastq/{sample}_R1.fastq.gz",
        read2="results/{project}/rename_fastq/{sample}_R2.fastq.gz"
    output:
        read1=temp("results/{project}/trim_fastq/{sample}_R1.trimmed.fastq.gz"),
        read2=temp("results/{project}/trim_fastq/{sample}_R2.trimmed.fastq.gz")
    params:
        overlap=config["overlap"],
        errate=config["errate"],
        adapter3=config["adapter3"],
        adapter5=config["adapter5"],
        minlen=config["minlen"],
        qscore=config["qscore"]
    log:
        "results/{project}/logs/trim_fastq/{sample}.log",
    threads: 4
    conda:
        "../envs/cutadapt.yaml"
    shell:
        "cutadapt -j {threads} -O {params.overlap} -e {params.errate} -m {params.minlen} -q {params.qscore},{params.qscore} -a {params.adapter3} -A {params.adapter5} -o {output.read1} -p {output.read2} {input.read1} {input.read2} >{log} 2>&1; "

rule trim_fastq_qc:
    input:
        read1="results/{project}/trim_fastq/{sample}_R1.trimmed.fastq.gz",
        read2="results/{project}/trim_fastq/{sample}_R2.trimmed.fastq.gz"
    output:
        out1="results/{project}/trim_fastq_qc/{sample}_R1.trimmed_fastqc.html",
        out2="results/{project}/trim_fastq_qc/{sample}_R2.trimmed_fastqc.html"
    log:
        "results/{project}/logs/trim_fastq_qc/{sample}.log"
    conda:
        "../envs/fastqc.yaml"
    threads: 4
    shell:
        "fastqc --outdir results/{project}/trim_fastq_qc --threads {threads} --quiet {input.read1} {input.read2} >{log} 2>&1"

rule bwa_align:
    input:
        read1="results/{project}/trim_fastq/{sample}_R1.trimmed.fastq.gz",
        read2="results/{project}/trim_fastq/{sample}_R2.trimmed.fastq.gz"
    output:
        sam=temp("results/{project}/bwa_align/{sample}.sam"),
        bam="results/{project}/bwa_align/{sample}.bam",
        bai="results/{project}/bwa_align/{sample}.bai",
        tmp=temp(directory("results/{project}/bwa_align/tmp{sample}"))
    resources:
        mem_mb=16000
    params:
        bwaidx=config["bwaidx"]
    log:
        bwa="results/{project}/logs/bwa_align/bwa.{sample}.log",
        picard="results/{project}/logs/bwa_align/picard.sortsam.{sample}.log"
    threads: 8
    conda:
        "../envs/bwa.yaml"
    shell:
        """bwa mem -M -t {threads} -R "@RG\\tID:{wildcards.sample}\\tLB:{wildcards.sample}\\tSM:{wildcards.sample}\\tPL:ILLUMINA" {params.bwaidx} {input.read1} {input.read2} >{output.sam} 2>{log.bwa}; """
        """picard SortSam SORT_ORDER=coordinate INPUT={output.sam} OUTPUT={output.bam} VALIDATION_STRINGENCY=LENIENT CREATE_INDEX=true TMP_DIR={output.tmp} >{log.picard} 2>&1; """

rule mark_dup:
    input:
        bam="results/{project}/bwa_align/{sample}.bam",
        bai="results/{project}/bwa_align/{sample}.bai"
    output:
        tmp=temp(directory("results/{project}/mark_dup/tmp{sample}")),
        reorder=temp("results/{project}/mark_dup/{sample}.reorder.bam"),
        qsort=temp("results/{project}/mark_dup/{sample}.qsorted.bam"),
        markdup=temp("results/{project}/mark_dup/{sample}.qsorted.markdup.bam"),
        metric="results/{project}/mark_dup/{sample}.markdup_metrics.txt",
        bam="results/{project}/mark_dup/{sample}.markdup.bam",
        bai="results/{project}/mark_dup/{sample}.markdup.bai"
    resources:
        mem_mb=16000
    params:
        refdict=config["refdict"]
    log:
        reorder="results/{project}/logs/mark_dup/picard.reorder.{sample}.log",
        qsort="results/{project}/logs/mark_dup/picard.qsort.{sample}.log",
        markdup="results/{project}/logs/mark_dup/picard.markdup.{sample}.log",
        csort="results/{project}/logs/mark_dup/picard.osort.{sample}.log"
    conda:
        "../envs/bwa.yaml"
    shell:
        """picard ReorderSam INPUT={input.bam} OUTPUT={output.reorder} SEQUENCE_DICTIONARY={params.refdict} VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.reorder} 2>&1; """
        """picard SortSam SORT_ORDER=queryname INPUT={output.reorder} OUTPUT={output.qsort} VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.qsort} 2>&1; """
        """picard MarkDuplicates INPUT={output.qsort} OUTPUT={output.markdup} METRICS_FILE={output.metric} ASSUME_SORT_ORDER=queryname VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.markdup} 2>&1; """
        """picard SortSam SORT_ORDER=coordinate INPUT={output.markdup} OUTPUT={output.bam} CREATE_INDEX=true VALIDATION_STRINGENCY=LENIENT TMP_DIR={output.tmp} >{log.csort} 2>&1; """

rule bam_qc:
    input:
        rawbam="results/{project}/bwa_align/{sample}.bam",
        rawbai="results/{project}/bwa_align/{sample}.bai",
        mdbam="results/{project}/mark_dup/{sample}.markdup.bam",
        mdbai="results/{project}/mark_dup/{sample}.markdup.bai"
    output:
        rawstat="results/{project}/bam_qc/{sample}.raw.bam.flagstat.txt",
        mdstat="results/{project}/bam_qc/{sample}.markdup.bam.flagstat.txt",
        insm="results/{project}/bam_qc/{sample}.insert_size_metrics.txt",
        insp="results/{project}/bam_qc/{sample}.insert_size_histogram.pdf"
    resources:
        mem_mb=16000
    log:
        samtools="results/{project}/logs/bam_qc/samtools.{sample}.log",
        picard="results/{project}/logs/bam_qc/picard.insertsize.{sample}.log"
    conda:
        "../envs/bwa.yaml"
    shell:
        """samtools flagstat {input.rawbam} >{output.rawstat} 2>{log.samtools}; """
        """samtools flagstat {input.mdbam} >{output.mdstat} 2>>{log.samtools}; """
        """picard CollectInsertSizeMetrics INPUT={input.mdbam} OUTPUT={output.insm} HISTOGRAM_FILE={output.insp} ASSUME_SORTED=True METRIC_ACCUMULATION_LEVEL=ALL_READS VALIDATION_STRINGENCY=LENIENT >{log.picard} 2>&1; """

rule base_coverage:
    input:
        bam=expand("results/{project}/mark_dup/{sample}.markdup.bam", project=config["project"], sample=config["read1"]),
        bai=expand("results/{project}/mark_dup/{sample}.markdup.bai", project=config["project"], sample=config["read1"])
    output:
        cov="results/{project}/base_coverage/base_coverage.txt.gz"
    params:
        bed=config["bed"]
    log:
        "results/{project}/logs/base_coverage/samtools.depth.log"
    threads: 8
    conda:
        "../envs/bwa.yaml"
    shell:
        "samtools depth -a -d 0 -Q 1 -@ {threads} -b {params.bed} {input.bam} >results/{project}/base_coverage/base_coverage.txt 2>{log}; "
        "gzip results/{project}/base_coverage/base_coverage.txt; "

#rule review_base_coverage:
#    input:
#        cov="results/{project}/base_coverage/{sample}.base_coverage.txt.gz"
#    output:
#        cov="results/{project}/base_coverage/{sample}.base_coverage.with_missing_bases.txt.gz",
#        sumcov="results/{project}/review_base_coverage/{sample}.base_coverage.summary.txt"
#    params:
#        bed=config["bed"]
#    log:
#        "results/{project}/logs/summarize_base_coverage/{sample}.log"
#    conda:
#        "../envs/python.yaml"
#    script:
#        "../scripts/review_base_coverage.py"

rule base_quality_recalibration:
    input:
        bam="results/{project}/mark_dup/{sample}.markdup.bam",
        bai="results/{project}/mark_dup/{sample}.markdup.bai"
    output:
        tmp=temp(directory("results/{project}/base_quality_recalibration/tmp{sample}")),
        recal="results/{project}/base_quality_recalibration/{sample}.recal_data.table",
        bam="results/{project}/base_quality_recalibration/{sample}.markdup.recal.bam"
    params:
        refseq=config["refseq"],
        snpdb=config["snpdb"]
    resources:
        mem_mb=16000
    log:
        br="results/{project}/logs/base_quality_recalibration/gatk.BaseRecalibrator.{sample}.log",
        ab="results/{project}/logs/base_quality_recalibration/gatk.ApplyBQSR.{sample}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk BaseRecalibrator --tmp-dir {output.tmp}  -I {input.bam} -R {params.refseq} --known-sites {params.snpdb} -O {output.recal} >{log.br} 2>&1; """
        """gatk ApplyBQSR --tmp-dir {output.tmp} -R {params.refseq}  -I {input.bam} --bqsr-recal-file {output.recal} -O {output.bam} >{log.ab} 2>&1; """

rule mutect_variant_calling:
    input:
        normal=get_normal_bam,
        tumor=get_tumor_bam,
        pon="results/{project}/create_panel_of_normals/pon.vcf.gz"
    output:
        tmp=temp(directory("results/{project}/mutect_variant_calling/tmp{pair}")),
        roa="results/{project}/mutect_variant_calling/{pair}/{pair}.f1r2.tar.gz",
        vcf="results/{project}/mutect_variant_calling/{pair}/{pair}.raw.vcf.gz"
    params:
        refseq=config["refseq"],
        gnomad=config["gnomad"],
        bed=config["bed"]
    resources:
        mem_mb=16000
    threads: 8
    log:
        "results/{project}/logs/mutect_variant_calling/gatk.mutect2.{pair}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """x=`basename {input.normal}`; """
        """sid=${{x%.markdup.recal.bam}}; """
        """mkdir -p {output.tmp}; """
        """gatk Mutect2 --tmp-dir {output.tmp} -R {params.refseq} """
        """-I {input.tumor} -I {input.normal} -normal ${{sid}} -L {params.bed} """
        """--panel-of-normals {input.pon} --germline-resource {params.gnomad} --f1r2-tar-gz {output.roa} -O {output.vcf} >{log} 2>&1; """

# LearnReadOrientationModel
rule learn_read_orientation_model:
    input:
        roa="results/{project}/mutect_variant_calling/{pair}/{pair}.f1r2.tar.gz"
    output:
        tmp=temp(directory("results/{project}/learn_read_orientation_model/tmp{pair}")),
        mdl="results/{project}/learn_read_orientation_model/{pair}/{pair}.read-orientation-model.tar.gz"
    resources:
        mem_mb=12000
    threads: 4
    log:
        "results/{project}/logs/learn_read_orientation_model/gatk.learnreadorientationmodel.{pair}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk LearnReadOrientationModel --tmp-dir {output.tmp} -I {input.roa} -O {output.mdl} >{log} 2>&1; """

# Run GetPileupSummaries to summarize read support for a set number of known variant sites.
rule get_pileup_summaries:
    input:
        normal=get_normal_bam,
        tumor=get_tumor_bam
    output:
        tmp=temp(directory("results/{project}/get_pileup_summaries/tmp{pair}")),
        normal="results/{project}/get_pileup_summaries/{pair}/{pair}.normal.pileups.table",
        tumor="results/{project}/get_pileup_summaries/{pair}/{pair}.tumor.pileups.table"
    params:
        exac=config["exac"]
    resources:
        mem_mb=16000
    threads: 4
    log:
        normal="results/{project}/logs/get_pileup_summaries/gatk.getpileupsummaries.{pair}.normal.log",
        tumor="results/{project}/logs/get_pileup_summaries/gatk.getpileupsummaries.{pair}.tumor.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk GetPileupSummaries --tmp-dir {output.tmp} -I {input.normal} """
        """-V {params.exac} -L {params.exac} -O {output.normal} >{log.normal} 2>&1; """
        """gatk GetPileupSummaries --tmp-dir {output.tmp} -I {input.tumor} """
        """-V {params.exac} -L {params.exac} -O {output.tumor} >{log.tumor} 2>&1; """

# Estimate contamination with CalculateContamination.
rule estimate_contamination:
    input:
        normal="results/{project}/get_pileup_summaries/{pair}/{pair}.normal.pileups.table",
        tumor="results/{project}/get_pileup_summaries/{pair}/{pair}.tumor.pileups.table"
    output:
        tmp=temp(directory("results/{project}/estimate_contamination/tmp{pair}")),
        seg="results/{project}/estimate_contamination/{pair}/{pair}.segments.tsv",
        ctm="results/{project}/estimate_contamination/{pair}/{pair}.contamination.table"
    resources:
        mem_mb=16000
    threads: 4
    log:
        "results/{project}/logs/estimate_contamination/gatk.estimatecontamination.{pair}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk CalculateContamination --tmp-dir {output.tmp} """
        """-I {input.tumor} -matched {input.normal} """
        """-tumor-segmentation {output.seg} -O {output.ctm} >{log} 2>&1; """

# pass the learned read orientation model to FilterMutectCallswith the -ob-priors argument
rule filter_mutect_calls:
    input:
        vcf="results/{project}/mutect_variant_calling/{pair}/{pair}.raw.vcf.gz",
        seg="results/{project}/estimate_contamination/{pair}/{pair}.segments.tsv",
        ctm="results/{project}/estimate_contamination/{pair}/{pair}.contamination.table",
        mdl="results/{project}/learn_read_orientation_model/{pair}/{pair}.read-orientation-model.tar.gz"
    output:
        tmp=temp(directory("results/{project}/filter_mutect_calls/tmp{pair}")),
        vcf="results/{project}/filter_mutect_calls/{pair}/{pair}.filtered.vcf.gz"
    params:
        refseq=config["refseq"]
    resources:
        mem_mb=16000
    threads: 4
    log:
        "results/{project}/logs/filter_mutect_calls/gatk.filtermutectcalls.{pair}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk FilterMutectCalls --tmp-dir {output.tmp} """
        """-R {params.refseq} -V {input.vcf} --tumor-segmentation {input.seg} --contamination-table {input.ctm} """
        """--ob-priors {input.mdl} -O {output.vcf} >{log} 2>&1; """

# Run Mutect2 in tumor-only mode for each normal sample, for creating PON
rule mutect_variant_calling_normal:
    input:
        bam="results/{project}/base_quality_recalibration/{normal}.markdup.recal.bam"
    output:
        tmp=temp(directory("results/{project}/mutect_variant_calling_normal/tmp{normal}")),
        vcf="results/{project}/mutect_variant_calling_normal/{normal}/{normal}.vcf.gz"
    params:
        refseq=config["refseq"],
        bed=config["bed"]
    resources:
        mem_mb=16000
    threads: 4
    log:
        "results/{project}/logs/mutect_variant_calling_normal/gatk.mutect2.{normal}.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk Mutect2 --tmp-dir {output.tmp} -R {params.refseq} """
        """-I {input.bam} -max-mnp-distance 0 -L {params.bed} """
        """-O {output.vcf} >{log} 2>&1; """

# Create a GenomicsDB from the normal Mutect2 calls.
rule create_genomicsdb_normal:
    input:
        vcf=expand("results/{project}/mutect_variant_calling_normal/{normal}/{normal}.vcf.gz", project=config["project"], normal=config["normal"])
    output:
        tmp=temp(directory("results/{project}/create_genomicsdb_normal/tmp")),
        db=temp(directory("results/{project}/create_genomicsdb_normal/pon_db"))
    params:
        refseq=config["refseq"],
        bed=config["bed"],
        vcf=get_normal_vcfs
    resources:
        mem_mb=12000
    threads: 4
    log:
        "results/{project}/logs/create_genomicsdb_normal/gatk.genomicsdbimport.normal.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk GenomicsDBImport --tmp-dir {output.tmp} -R {params.refseq} -L {params.bed} """
        """--genomicsdb-workspace-path {output.db} --merge-input-intervals {params.vcf} >{log} 2>&1; """

# Combine the normal calls using CreateSomaticPanelOfNormals.
rule create_panel_of_normals:
    input:
        db="results/{project}/create_genomicsdb_normal/pon_db"
    output:
        tmp=temp(directory("results/{project}/create_panel_of_normals/tmp")),
        vcf="results/{project}/create_panel_of_normals/pon.vcf.gz"
    params:
        refseq=config["refseq"],
        gnomad=config["gnomad"]
    resources:
        mem_mb=12000
    threads: 4
    log:
        "results/{project}/logs/create_panel_of_normals/gatk.createsomaticpanelofnormals.log"
    conda:
        "../envs/gatk.yaml"
    shell:
        """mkdir -p {output.tmp}; """
        """gatk CreateSomaticPanelOfNormals -R {params.refseq} -V gendb://{input.db} -O {output.vcf} >{log} 2>&1; """

